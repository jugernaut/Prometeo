{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5.1 Las ecuaciones normales y Método de Cholesky: sus inconvenientes.",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNbYrS+Gx8jGuA3M/+8FYdH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/Prometeo/blob/desarrollo/06_AnalisisNumerico/05_carpetanueva/5_1_Las_ecuaciones_normales_y_M%C3%A9todo_de_Cholesky_sus_inconvenientes_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zCGcquO81sg"
      },
      "source": [
        "#**Mínimos Cuadrados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JspT0ijx_wyV"
      },
      "source": [
        "*Ejemplo*: Ajustar una recta $y=p \\cdot x + d$ dados los puntos 7 puntos: $(x_i , y_i)$\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Prometeo/blob/desarrollo/Figuras/1.jpeg?raw=1\" width=\"600\">\n",
        "</center>\n",
        "\n",
        "Estimar los parámetros $p,d$ \n",
        "\n",
        "$\\quad$\n",
        "\n",
        "$$\\textbf{Modo Lineal}$$ \n",
        "\n",
        "<center>\n",
        "$y_1 = d + p \\cdot x_1 + \\in_1,$ \n",
        "\n",
        "$y_2 = d + p \\cdot x_2 + \\in_2,$ \n",
        "\n",
        "$y_3 = d + p \\cdot x_3 + \\in_3,$\n",
        "\n",
        "$y_4 = d + p \\cdot x_4 + \\in_4,$ \n",
        "\n",
        "$y_5 = d + p \\cdot x_5 + \\in_5,$\n",
        "\n",
        "$y_6 = d + p \\cdot x_6 + \\in_6,$ \n",
        "\n",
        "$y_7 = d + p \\cdot x_7 + \\in_7,$ \n",
        "</center>\n",
        "\n",
        "$\\quad$ \n",
        "\n",
        "siendo $\\in_1 , ... , \\in_7$ errores aleatorios. \n",
        "\n",
        "$\\quad$\n",
        "\n",
        "\n",
        "Estimar los parámetros $p,d$\n",
        "\n",
        "$\\quad$\n",
        "\n",
        "$$\\textbf{Modo Lineal}$$\n",
        "\n",
        "$$\\begin{pmatrix} y_1\\\\ \\vdots \\\\y_7 \\end{pmatrix} = \\begin{pmatrix} 1 & x_1\\\\ \\vdots & \\vdots\\\\ 1 & x_7 \\end{pmatrix} \\begin{pmatrix} d\\\\ p \\end{pmatrix} + \\begin{pmatrix} \\epsilon_1\\\\ \\vdots \\\\ \\epsilon_7 \\end{pmatrix} $$\n",
        "\n",
        "$\\quad$\n",
        "\n",
        "Estimar los parámetros $p,d$\n",
        "\n",
        "$\\quad$ \n",
        "\n",
        "$$\\textbf{Modo Lineal}$$ \n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Prometeo/blob/desarrollo/Figuras/3.jpeg?raw=1\" width=\"600\">\n",
        "</center>\n",
        "\n",
        "\n",
        "\n",
        "$\\bullet$ Número de ecuaciones > Número de parámetros \n",
        "\n",
        "$\\bullet$ Columnas de matriz $X$ son linealmente independientes\n",
        "\n",
        "$\\quad$\n",
        "\n",
        "Estimar los parámetros $p,d$ $\\to$ estimador $\\hat{\\beta}$ para $\\beta$ \n",
        "\n",
        "<center>\n",
        "\n",
        "minimizar tamaño de \n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Prometeo/blob/desarrollo/Figuras/4.jpeg?raw=1\" width=\"300\">\n",
        "</center>\n",
        "\n",
        "Como ajustamos reta $y=d + p \\cdot x$, \n",
        "\n",
        "$min_{\\beta \\in \\mathbb R^2}$ $\\parallel X \\beta - y \\parallel_2^2$ = $min_{d,p \\in \\mathbb R}$ $\\sum_{i=1}^{7} (y_i - (d + p \\cdot x_i))^2$\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Prometeo/blob/desarrollo/Figuras/5.jpeg?raw=1\" width=\"700\">\n",
        "</center>\n",
        "\n",
        "Buscar vector $X \\beta$ en la imagen de matrix $X$ tal que la distancia $\\parallel X \\beta - y \\parallel _2$ sea mínima.\n",
        "\n",
        "$$f (\\beta) : = \\parallel X \\beta - y \\parallel _2^2$$\n",
        "\n",
        "$$\\textbf{Problema Lineal de Mínimos Cuadrados}$$\n",
        "\n",
        "$$min_{\\beta \\in \\mathbb R^2} f (\\beta)$$\n",
        "\n",
        "Hallar puntos críticos: puntos donde el gradiente de $f$ es cero\n",
        "\n",
        "$$\\bigtriangledown f (\\beta) = 0$$\n",
        "\n",
        "$$f(\\beta) := \\parallel X \\beta - y \\parallel _2^2$$\n",
        "\n",
        "$$\\textbf{Problema Lineal de Mínimos Cuadrados}$$\n",
        "\n",
        "$$min_{\\beta \\in \\mathbb R^2} f (\\beta)$$\n",
        "\n",
        "Hallar puntos críticos:\n",
        "\n",
        "$$\\parallel X \\beta - y \\parallel _2^2 = \\beta^T X^T X \\beta - 2 \\beta^T X^T y + y^Ty$$\n",
        "\n",
        "$$\\Longrightarrow \\bigtriangledown f(\\beta) = 2X^T X \\beta - 2X^T y$$\n",
        "\n",
        "$$f(\\beta) := \\parallel X\\beta - y \\parallel _2^2$$\n",
        "\n",
        "$$\\textbf{Problema Lineal de Mínimos Cuadrados}$$\n",
        "\n",
        "$$min_{\\beta \\in \\mathbb R^2} f (\\beta)$$\n",
        "\n",
        "Hallar puntos críticos:\n",
        "\n",
        "$$ \\bigtriangledown f(\\beta) = 0 \\Longleftrightarrow X^T X\\beta = X^T y$$\n",
        "\n",
        "El estimador de cuadrados mínimos $\\hat{\\beta}$ para $\\beta$ dado por la solución de $\\color{blue}{Ecuaciones\\ Normales}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7KIFxV8aHRi"
      },
      "source": [
        "#**Ecuaciones Normales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6_WoNXeaNEQ"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Prometeo/blob/desarrollo/Figuras/6.jpeg?raw=1\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "Usar matriz $X$ del modelo lineal en ecuaciones normales\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Prometeo/blob/desarrollo/Figuras/7.jpeg?raw=1\" width=\"600\">\n",
        "</center>\n",
        "\n",
        "¿Las ecuaciones normales tienen solución única?\n",
        "\n",
        "En este caso, sí \n",
        "\n",
        "columnas de $X$ son linealmente independientes $\\Longrightarrow$ $X^T X$ positiva definida \n",
        "\n",
        "Estimador de Cuadrados Mínimos \n",
        "\n",
        "$$\\hat{\\beta} = (X^T X)^{-1} X^T y$$\n",
        "\n",
        "$$\\binom{d}{p} = \\binom{0.6831}{1.4353}$$\n",
        "\n",
        "Facrtorización LU \n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Prometeo/blob/desarrollo/Figuras/8.jpeg?raw=1\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "1. $L \\varepsilon = X^T$ y por sustitución directa \n",
        "\n",
        "(*)\n",
        "\n",
        "2. $U \\hat{\\beta} = \\varepsilon$ por sustitución hacia atras.\n",
        "\n",
        "(*)\n",
        "\n",
        "$\\color{black}{Ejemplo\\ }$ : Ajuste una cuadrática $y = c + b \\cdot x + a \\cdot x^2$ por los 7 puntos \n",
        "\n",
        "$$\\textbf{Modelo Lineal}$$\n",
        "\n",
        "$$y_i = c + b \\cdot x_i + a \\cdot x_i^2 + \\epsilon , i=1,...7$$\n",
        "\n",
        "$$\\begin{pmatrix}\n",
        "0 \\\\ \n",
        "6 \\\\ \n",
        "7.9 \\\\\n",
        "8.5 \\\\ \n",
        "12 \\\\\n",
        "21.5 \\\\ \n",
        "35 \\\\\n",
        "\\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0\\\\ 1 & 2 & 2^2\\\\ 1 & 5 & 5^2\\\\ 1 & 7 & 7^2\\\\ 1 & 9 & 9^2\\\\ 1 & 13 & 13^2\\\\ 1 & 24 & 24^2 \\end{pmatrix}  \\begin{pmatrix} c\\\\ b\\\\ a  \\end{pmatrix} + \\begin{pmatrix} \\epsilon_1\\\\ \\vdots\\\\ \\epsilon_7 \\end{pmatrix}$$\n",
        "\n",
        "$$y = X \\quad  \\quad  \\quad  \\quad  \\quad  \\quad  \\quad  \\quad   \\beta + \\epsilon$$\n",
        "\n",
        "<center>\n",
        "\n",
        "Hallar estimador de cuadrados mínimos $\\hat{\\beta}$ para $\\beta$\n",
        "\n",
        "</center>\n",
        "\n",
        "$$\\downarrow$$\n",
        "\n",
        "<center>\n",
        "\n",
        "Problema Lineal de cuadrados mínimos\n",
        "\n",
        "</center>\n",
        "\n",
        "$$min_{\\beta \\in \\mathbb R} \\parallel X \\beta - y \\parallel _2^2$$\n",
        "\n",
        "$$\\downarrow$$\n",
        "\n",
        "<center>\n",
        "\n",
        "Ecuaciones Normales\n",
        "\n",
        "</center>\n",
        "\n",
        "$$X^T X \\beta = X^T y$$\n",
        "\n",
        "$\\quad$ \n",
        "\n",
        "\n",
        "$$\\begin{pmatrix} 1 & 1 & 1 & 1 & 1 & 1 & 1\\\\ 0 & 2 & 5 & 7 & 9 & 13 & 24\\\\ 0 & 2^2 & 5^2 & 7^2 & 9^2 & 13^2 & 24^2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0\\\\ 1 & 2 & 2^2\\\\ 1 & 5 & 5^2\\\\ 1 & 7 & 7^2\\\\ 1 & 9 & 9^2\\\\ 1 & 13 & 13^2\\\\ 1 & 24 & 24^2 \\end{pmatrix}  \\begin{pmatrix} c\\\\ b\\\\ a \\end{pmatrix} = \\begin{pmatrix} 1 & 1 & 1 & 1 & 1 & 1 & 1\\\\ 0 & 2 & 5 & 7 & 9 & 13 & 24\\\\ 0 & 2^2 & 5^2 & 7^2 & 9^2 & 13^2 & 24^2 \\end{pmatrix} \\begin{pmatrix} 0\\\\ 6\\\\ 7.9\\\\ 8.5\\\\ 12\\\\ 21.5\\\\ 35\\\\ \\end{pmatrix}$$\n",
        "\n",
        "$$X^T X \\beta = X^T y$$\n",
        "\n",
        "$$\\downarrow$$\n",
        "\n",
        "$$\\begin{pmatrix} 7 & 60 & 904\\\\ 60 & 904 & 17226\\\\ 904 & 17226 & 369940 \\end{pmatrix} \\begin{pmatrix} c\\\\ b\\\\ a\\\\ \\end{pmatrix} = \\begin{pmatrix} 90.9\\\\ 1338.5\\\\ 25404\\\\ \\end{pmatrix}$$\n",
        "\n",
        "Como $XX^T$ es simétrica y positiva definida acepta solución por Factorización de Cholesky.\n",
        "\n",
        "$$\\begin{pmatrix} c\\\\ b\\\\ a\\\\ \\end{pmatrix} = \\begin{pmatrix} 0.8977\\\\ 1.3695\\\\ 0.0027\\\\ \\end{pmatrix}$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXKi_0NXhuxQ"
      },
      "source": [
        "#**Mínimos Cuadrados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa5UEcWGh5Bk"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Prometeo/blob/desarrollo/Figuras/9.jpeg?raw=1\" width=\"600\">\n",
        "</center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFVAttjyi_x3"
      },
      "source": [
        "#**Aproximación por mínimos cuadrados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQUN65chjGtg"
      },
      "source": [
        "Supongamos que tenemos observaciones \n",
        "\n",
        "$$y(x) = f(c_1, c_2, ... , c_n) \\quad \\quad (1)$$\n",
        "\n",
        "donde $x$ es el parámetro que describe el cambio y $c_1, c_2,...,c_n$ son $n$ cantidades desconocidas llamadas parámetros del modelo cuyos valores queremos determinar. En particular consideremos el caso en que el modelo es *lineal* en sus parámetros y por lo tanto se puede expresar como: \n",
        "\n",
        "$$f(c_1, c_2, ..., c_n) = \\sum_{j=1}^{n} c_j \\phi_j (x) \\quad \\quad (2)$$\n",
        "\n",
        "para *n* funciones $\\phi_j (x)$ del parámetro *x*. Un conjunto de *m* observaciones de *f* proverá de valores medidos $y_i$ afectados de errores $\\epsilon_i$.\n",
        "\n",
        "$$y_i = y(x_i) + \\epsilon_i \\quad \\quad (3)$$\n",
        "\n",
        "$$y_i = \\sum_{j=1}^{n} c_j \\phi_j (x_i) + \\epsilon_i , \\quad i=1,2,...,m \\quad \\quad (4)$$\n",
        "\n",
        "Esto se puede ver como: \n",
        "\n",
        "$$\\begin{pmatrix} y_1\\\\ y_2\\\\ \\vdots \\\\y_n \\end{pmatrix} = \\begin{pmatrix} \\phi_1 (x_1) & \\phi_2 (x_1)& ... & \\phi_n (x_1)\\\\ \\phi_1 (x_2) & \\phi_2 (x_2)& ... & \\phi_n (x_2)\\\\ \\cdots & & \\ddots & \\cdots\\\\ \\phi_1 (X_m) & \\phi_2 (X_m) & ... & \\phi_n (X_m) \\end{pmatrix}  \\begin{pmatrix} c_1\\\\ c_2\\\\ \\vdots\\\\ c_n \\end{pmatrix} + \\begin{pmatrix} \\epsilon_1\\\\ \\epsilon_2\\\\ \\vdots\\\\ \\epsilon_n \\end{pmatrix} \\quad \\quad (5)$$\n",
        "\n",
        "Como $m>n$, el sistema $y=Ac$ es sobre determinado y por lo tanto, tendrá solución sólo si el vector de datos y se encuentra en el espacio imágen de la matriz $A$, denotado como $lm(A)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VA84RIvqHzK"
      },
      "source": [
        "#**Matriz de diseño**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0pbzCsIqNJV"
      },
      "source": [
        "Definiendo $A$ como la matriz de diseño de elementos $a_{ij} = \\phi_j (x_i)$, \n",
        "\n",
        "1. El vector de parámetros *x* de tamaño $nx1$ de elementos $c_i$;\n",
        "\n",
        "2. Las *funciones base* $\\phi_i(x)$ pueden ser funciones no-lineales de *x+.\n",
        "\n",
        "3. El vector de observaciones (o medidas) $y_i$ (de tamaño $m x 1$) *y*, estos aparecen de forma lineal;\n",
        "\n",
        "4. El vector (de tamaño $m x 1$) de residuos *r* (los elementos $\\epsilon_i$) pueden escribirse matricialmente como:\n",
        "\n",
        "$$Ax + r = y \\quad \\quad (6)$$\n",
        "\n",
        "Esta relación constituye nuetsro modelo lineal de elas observaciones. Si $m \\geq n$ (más observaciones que parámetros) se trata de determinar el conjunto de parámetros *x* que satisfaga mejor en algún sentido lineal, el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9u8u6B2sVnI"
      },
      "source": [
        "#**Las funciones base**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yhBkwJOsaRl"
      },
      "source": [
        "Dependiendo del problema en particular, las *funciones base* $\\phi_i (x)$ se pueden elegir de muchas formas. Algunas eleccions comunes pueden ser: \n",
        "\n",
        "1. Polinomios:\n",
        "\n",
        "$$\\phi_j(t) = t^{j-1}, \\quad j=1,...,n$$\n",
        "$$y(t) = \\beta_1 t^{n-1} + ... + \\beta_{n-1}t \\quad \\quad \\quad \\quad (7)$$\n",
        "\n",
        "2. Funciones racionales: \n",
        "\n",
        "$$\\phi_j(t) = \\frac{t^{j-1}}{\\alpha_0 + \\alpha_1t + ... + \\alpha_{n-1}t^{n-1}}$$ \n",
        "\n",
        "$$y(t) = \\frac{\\beta_1t^{j-1} + ... + \\beta_{n-1}t + \\beta_n}{\\alpha_0 + \\alpha_1t + ... + \\alpha_{n-1}t^{n-1}} \\quad \\quad (8)$$\n",
        "\n",
        "con $\\alpha_0 ,..., \\alpha_n$ parámetros dados.\n",
        "\n",
        "3. Exponenciales:\n",
        "\n",
        "$$\\phi_j (t) = e^{-\\lambda_jt}$$\n",
        "\n",
        "$$y(t) = \\beta_1e^{-\\lambda_1t} + ... + \\beta_ne^{-\\lambda_nt} \\quad \\quad (9)$$\n",
        "\n",
        "con $\\lambda_j$ parámetros de decaimiento.\n",
        "\n",
        "4. Gaussianas:\n",
        "\n",
        "$$\\phi_j(x) = e^{-(\\frac{t-\\mu_j}{\\sigma_j})}$$\n",
        "\n",
        "$$y(t) = \\beta_1 e^{-(\\frac{t-\\mu_j}{\\sigma_1})} + ... + \\beta_n e^{-(\\frac{t-\\mu_n}{\\sigma_n})} \\quad \\quad (10)$$ \n",
        "\n",
        "Si las *funciones base* $\\phi_i(x)$ son polinomios monomiaes, tenemos que la ecuación $(5)$ queda como matriz de Vandermonde:\n",
        "\n",
        "$$\\begin{pmatrix} y_1\\\\ y_2\\\\ \\vdots \\\\ y_n \\end{pmatrix} = \\begin{pmatrix} 1 & x_1 & x_1^2 & ... & x_1^n\\\\ 1 & x_2 & x_2^2 & ... & x_2^n\\\\ \\vdots & & &\\ddots & \\vdots\\\\ 1 & x_m & x_m^2 & ... & x_m^n \\end{pmatrix} \\begin{pmatrix} c_1\\\\ c_2\\\\ \\vdots \\\\ c_n \\end{pmatrix} + \\begin{pmatrix} \\epsilon_1\\\\ \\epsilon_2\\\\ \\vdots\\\\ \\epsilon_n \\end{pmatrix} \\quad \\quad (11)$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0nYUASmyTY3"
      },
      "source": [
        "#**Minimizar los residuos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uBr4Ff9yW9G"
      },
      "source": [
        "Para el método de mínimos cuadrados, los estimadores de mínimos cuadrados de los parámetros son aquellos valores que minimizan la norma euclidiana de los residuos \n",
        "\n",
        "$$ \\parallel r\\parallel_2 = \\parallel b - Ax \\parallel_2 = (r´r)^{1/2} \\quad \\quad (12)$$ \n",
        "\n",
        "Este requisito conduce a que la solución de mínimos cuadrados debe de satisfacer las ecuaciones normales\n",
        "\n",
        "$$(A^T A) x = A^T b \\quad \\quad (13)$$\n",
        "\n",
        "de donde se sigue que cuando $A^T A$ es no singular, solución de mínimos cuadrados $\\color{blue}{existe\\ y\\ es\\ única}$. La condición necesaria y suficiente para la existencia de solución única es que las columnas de la matriz $A$ sean linealmente independientes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UheJiEULz9SE"
      },
      "source": [
        "#**Proyección ortogonal**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRSed4LB0F8k"
      },
      "source": [
        "Suponiendo que y no pertenece a la imagen de $A = lm(A)$ denotamos como:\n",
        "\n",
        "$$P_A : \\mathbb R^m \\to lm(A) \\quad \\quad (14)$$\n",
        "\n",
        "a la proyección ortogonal que mapea $\\mathbb R^m$ sobre $lm(A)$. Entonces el valor de *x* que minimiza la norma de $r = b -Ax$ es aquel que satisface $Ax = P_ab$\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Prometeo/blob/desarrollo/Figuras/10.jpeg?raw=1\" width=\"600\">\n",
        "</center>\n",
        "\n",
        "Buscar el vector $A_x$ en la imagen de matriz $A$ tal que la distancia $\\parallel A_X - b \\parallel_2$ sea mínima. En otras palabras el residual $r=b - A_x$ debe de ser ortogonal al espacio de $lm(A)$.\n",
        "\n",
        "Por otro lado, el espacio $lm(A)$ es generado por los vectores columna de $A$, es decir:\n",
        "\n",
        "$$lm(a) = gen\\{a_1, a_2, ... , a_n\\} \\quad \\quad (15)$$\n",
        "\n",
        "donde $a_i$ denota al i-ésimo vector columna de $A$. Esto debido a que si $x=(x_1,x_2,...,x_n)^T$, entonces $Ax = x_1a_1 + x_2a_2 + ... + x_2a_n$.\n",
        "\n",
        "$\\color{blue}{Proposición }$ \n",
        "\n",
        "El residual $r = y - Ac$ es ortogonal al espacio $lm(A)$ si y sólo si \n",
        "\n",
        "$$A^T A_c = A^T y \\quad \\quad (16)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9tuLmKL3gb8"
      },
      "source": [
        "#**Ecuaciones Normales para el problema de mínimos cuadrados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTX9ZGuL3mlB"
      },
      "source": [
        "$\\color{blue}{Demostración }$ \n",
        "\n",
        "1. El residual $r$ es ortogonal a $lm(A)$ si y sólo si $a_i^T r = 0$ para toda $i=1,2,...,n$.\n",
        "\n",
        "2. Por lo tanto $r$ es ortogonal a $lm(A) \\Leftrightarrow A^Tr = A^T (y-Ac) = 0$ \n",
        "\n",
        "3. De aquí se sigue que $r$ es ortogonal a $lm(A)$ $\\Leftrightarrow$ se satisface $(16)$.\n",
        "\n",
        "Al sistema de ecuaciones: \n",
        "\n",
        "$$A^T A_c = A^T y \\quad \\quad (17)$$\n",
        "\n",
        "se le conoce como $\\color{blue}{Ecuaciones\\ Normales }$ para el problema de mínimos cuadrados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh_ItvKf5YT7"
      },
      "source": [
        "#**Teorema de mínimos cuadrados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxEK0aL-5cRk"
      },
      "source": [
        "$\\color{green}{Rango\\ de\\ una\\ matriz}$ \n",
        "\n",
        "El número de columnas linealmente independientes de una matriz $A$ (*m* renglones y *n* columnas) es igual a la dimensión del espacio columna de $A$. También la dimensión del espacio renglón determinar el rango. El rango de $A$ será, por lo tanto, un número no negativo, menor o igual que el mínimo entre m y n:\n",
        "\n",
        "$$A \\in M_{mxn} \\Rightarrow 0 ≤ rang (A) ≤ min(m,n) \\quad \\quad (18)$$\n",
        "\n",
        "$\\color{blue}{Teorema }$ \n",
        "\n",
        "Si la matriz $A$ (de m x n) tiene rango completo, entonces $A^T A$ es una matriz cuadrada no singular, simétrica y definida positiva.\n",
        "\n",
        "$\\color{blue}{Demostración: }$\n",
        "\n",
        "1. La matriz $A$ es de tamaño $m x n$ por lo tanto $A^T$ es de tamaño $n x m$. La matriz $A^T A$ es cuadrada (de tamaño n x n) y simétrica.\n",
        "\n",
        "2. Si $A$ es de rango completo esto implica que $A^TA$ es no singular. Basta demostrar que si $A^T A$ es singular entonces el rango es deficiente:\n",
        "\n",
        "$A^T A$ singular: \n",
        "\n",
        "$\\Rightarrow A^T Ax = 0$ para algún vector $x \\neq 0, x \\in \\mathbb R^n$\n",
        "\n",
        "$\\Rightarrow x^T A^T Ax = 0, x \\neq 0$\n",
        "\n",
        "$\\Rightarrow \\parallel Ax \\parallel_2^2 = 0, x \\neq 0$\n",
        "\n",
        "$\\Rightarrow Ax = 0 , x \\neq 0$\n",
        "\n",
        "$\\Rightarrow$ $A$ es singular\n",
        "\n",
        "$\\Rightarrow$ $A$ tiene rango deficiente $\\quad \\quad (19)$\n",
        "\n",
        "Como $x \\neq 0, x \\in \\mathbb R^n$, entonces como $A^T A$ no es singular, se satisface $x^T A^T Ax = \\parallel Ax \\parallel _2^2 > 0$. Se concluye que $A^T A$ debe ser definida positiva. Por lo tanto, se reduce que si la matriz $A$ es de rango completto, entonces la solución del sistema de ecuaciones normales $A^T Ac = A^T$ y debe ser única e igual a \n",
        "\n",
        "$$c = (A^T A)^{-1} A^T y$$\n",
        "\n",
        "A la matriz: \n",
        "\n",
        "$$A^T = (A^T A)^{-1} A^T$$\n",
        "\n",
        "se le llama $\\color{blue}{Pseudoinversa\\ o\\ inversa\\ generalizada\\ de\\ Penrose }$ además como $c = A^t$ y entonces $A_c = AA^t$ y por lo tanto, la matriz:\n",
        "\n",
        "$$P_A = AA^t = A(A^T A)^{-1} A^T$$\n",
        "\n",
        "es la matriz de proyección sobre el espacio $lm(A)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWo2rrVu96Ed"
      },
      "source": [
        "#**Matriz Pseudoinversa**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTcngFjW-GYp"
      },
      "source": [
        "Ejemplo: Encontrar la pseudoinversa de la matriz:\n",
        "\n",
        "$$A = \\begin{pmatrix} 1 & 1\\\\ 1 & 2\\\\ 1 & 3 \\end{pmatrix} \\quad \\quad (20)$$\n",
        "\n",
        "Tenemos que: \n",
        "\n",
        "$$A^t = (A^T A)^{-1} A^T = \\begin{pmatrix} \\frac{7}{3} & -1\\\\ -1 & \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} 1 & 1 & 1\\\\ 1 & 2 & 3 \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{3} & \\frac{1}{3} & - \\frac{2}{3}\\\\ -\\frac{1}{2} & 0 & \\frac{1}{2} \\end{pmatrix} \\quad \\quad (21)$$\n",
        "\n",
        "La solución de mínimos cuadrados $Ax = b$ está dada por:\n",
        "\n",
        "$$x = A^tb \\quad \\quad (22)$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEA-Fz7o_lJt"
      },
      "source": [
        "#**Algoritmo de Ecuaciones Normales para resolver Ax=b**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkJ1riHr_yWF"
      },
      "source": [
        "Dada la matriz de diseño $A$ de tamaño $m x n$ de rango completo y el vector de datos $b \\in \\mathbb R^n$\n",
        "\n",
        "1. Calcular $A^T A$\n",
        "\n",
        "2. Calcular la factorización de Cholesky $A^T A = LL^T$\n",
        "\n",
        "3. Resolver para $z \\in \\mathbb R^n$ el sistema \n",
        "triangular inferior $Lz = A^T b$, con sistitución hacia adelante.\n",
        "\n",
        "4. Resolver para $x \\in \\mathbb R^n$ el sistema triangulasr superior $L^Tx = Az$, con sustitución hacia atrás.\n",
        "\n",
        "$\\quad$\n",
        "\n",
        "En la práctica muy a menudo las columnas son aproximadamente linealmente independientes, lo cual produce un sisteema de ecuaciones normales con una matriz mal condicionada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTtZjMppA3Fx"
      },
      "source": [
        "#**Bibliografía**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bybp6-xHA6YJ"
      },
      "source": [
        "1. Ake Björck. Numerical methods for leastg squares problems. SIAM, 1996.\n",
        "\n",
        "2. Ipsen I. C. F. Numerical Matrix Analysis Linear Systems and Least Squares. SIAM\n",
        "\n",
        "3. L. Héctor Juárez y Assaely Léon. Álgebra Lineal Numérica, Mínimos Cuadrados y Optimización. 4to Coloquio del Departamento de Matemáticas UAM.\n",
        "\n",
        "4. Biswa Nath Datta, Numerical Linear Algebra and Appliactions Cole Publications, 1995.\n",
        "\n",
        "5. Gene H. Golub, Charles F., Matrix Computations, the Johns Hopkins University Press, Third edition\n",
        "\n",
        "6. Poole, David. Algebra Lineal. Una Introducción Moderna /3 Ed. 2011.\n",
        "\n",
        "7. Cleve B. Moler. Numerical Computing with MATLAB. SIAM, 2004."
      ]
    }
  ]
}